
<!-- <!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"> -->



<head>
    <!-- <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> -->
    <meta charset=UTF-8">

    <!-- analysis -->
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?701e4aa204e327f6c601e404cba1e34e";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
        })();
    </script>
    
    
    <!-- Meta tags for search engines to crawl -->
    <meta name="robots" content="index,follow">
    <meta name="keywords" content="Rong Li; 3D Computer Vision; Point Clouds; South China University of Technology; SCUT">
    <script src="assets/js/jquery.min.js"></script>

    <!-- https://cn.office-converter.com/Free-Online-ICO-Convert -->
    <link rel="icon" href="./home_files/icons-whale.ico" type="image/x-icon">

    <title>Rong Li</title>
    <style>

        @media screen and (max-device-width: 480px) {
            body {
                -webkit-text-size-adjust: none;
                /* zoom:0.5 */
            }
        }

        /* 正文字号 */
        p {
            font-size: 16px;
        }


        h1 {
            font-size: 30px;
            margin: 0;
            padding: 0;
        }

        /* 标题字号 */
        h2 {
            font-size: 20px;
            margin: 0;
            padding: 0;
        }

        h3 {
            font-size: 18px;
            margin: 8;
            padding: 0;
        }

        body {
            padding: 0;
            font-family: Arial;
            font-size: 16px;
            background-color: rgb(231, 242, 255);
        }

        .title {
            /* width: 650px; */
            width: 750px;
            margin: 20px auto;
        }

        .container {
            /* width: 750px; */
            width: 850px;
            margin: 20px auto;
            border-radius: 10px;
            background-color: #fff;
            padding: 20px;
            clear: both;
        }

        .container_title {
            /* width: 750px; */
            width: 850px;
            margin: 20px auto;
            border-radius: 10px;
            padding: 20px;
            clear: both;
        }

        .iframe_video {
            float: left;
            margin-right: 30px
        }

        #bio {
            padding-top: 20px;
            /* margin-right: 25px; */
            /* text-align: justify; */
            /* text-justify: inter-word; */
        }

        #me {
            border: 0 solid black;
            margin-bottom: 50px;
            border-radius: 10px;
        }

        #sidebar {
            margin-left: 25px;
            margin-right: 50px;
            border: 0 solid black;
            float: left;
            margin-bottom: 0;
        }

        a {
            text-decoration: none;
        }

            a:hover {
                text-decoration: underline;
            }

            a, a:visited {
                color: #0050e7;
            }
        
        /* 最上面的栏目 */
        .topbar {
            font-size: 20px;
            margin: 0;
            padding: 0;
        }
            .topbar strong a {
                /* color: #0000A0; */
                color: black;
                display: inline-block;
                vertical-align: middle;
                -webkit-transform: perspective(1px) translateZ(0);
                transform: perspective(1px) translateZ(0);
                box-shadow: 0 0 1px rgba(0, 0, 0, 0);
                /* -webkit-transition-duration: 0.1s; */
                /* transition-duration: 0.1s; */
                -webkit-transition-property: transform;
                transition-property: transform;

            }
            .topbar strong a:hover {
                    /* 下划线 */
                    /* text-decoration: none; */
                    -webkit-transform: scale(1.05);
                    transform: scale(1.05);
                    }


        .publogo {
            width: 100 px;
            margin-right: 20px;
            float: left;
            border: 0;
        }

        .publication {
            clear: left;
            padding-bottom: 0px;
        }

            .publication p {
                height: 100px;
                padding-top: 5px;
            }

            /* 论文和项目的标题 */
            .publication strong{
                /* color: #0000A0; */
                /* color: black; */
                font-size: 16px;
            }

            /* 代码论文链接 */
            .publication .links {
                /* font-size: 14px; */
                position: relative;
                top: 10px;
            }

                .publication .links a {
                    /*链接字体*/
                    font-size: 12px;
                    margin-right: 20px;
                    /* 边框样式 */
                    border-style:solid;
                    border-width: 1px;
                    border-radius: 5px;
                    /* 内边距 */
                    padding-right: 5px; 
                    padding-left: 5px;
                    padding-top: 1px;
                    padding-bottom: 1px;
                    /* outline-offset: -1px; */
                    /* 悬浮相关 */
                    display: inline-block;
                    vertical-align: middle;
                    -webkit-transform: perspective(1px) translateZ(0);
                    transform: perspective(1px) translateZ(0);
                    box-shadow: 0 0 1px rgba(0, 0, 0, 0);
                    /* -webkit-transition-duration: 0.1s; */
                    /* transition-duration: 0.1s; */
                    -webkit-transition-property: transform;
                    transition-property: transform;
                }
                /* 鼠标悬浮样式 */
                .publication .links a:hover {
                    /* 下划线 */
                    text-decoration: none;
                    -webkit-transform: scale(1.05);
                    transform: scale(1.05);
                    }


        .codelogo {
            margin-right: 10px;
            float: left;
            border: 0;
        }

        .code {
            clear: left;
            padding-bottom: 10px;
            vertical-align: middle;
        }

            .code .download a {
                display: block;
                margin: 0 15px;
                float: left;
            }

            .code strong a {
                color: #000;
            }

        .external a {
            /* margin: 0 10px; */
            margin-left:auto; 
            margin-right:auto;
        }
    </style>
</head>

<body>
    
    <div class="container">
        <div class="topbar">
        <strong>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="./home.html">Home</a>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <!-- <a href="./publications.html">Publications</a> -->
            <!-- &nbsp;&nbsp;&middot;&nbsp;&nbsp; -->
            <a href="#publications">Publications</a>
            <!-- &nbsp;&nbsp;&middot;&nbsp;&nbsp; -->
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

            <a href="#projects">Projects</a>
            <!-- &nbsp;&nbsp;&middot;&nbsp;&nbsp; -->
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <!-- <a href="./more.html">More</a> -->
            <a href="#experience">Experience</a>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <!-- <a href="./more.html">More</a> -->
            <a href="#contact">Contact</a>
        </strong>
        </div>
    </div>

    <div class="container">
        <div id="sidebar">
            <img src="./home_files/rong_img.jpg" vspace="50 px" width="250 px" id="me" itemprop="photo" />
        </div>
        <div id="bio">

            <br />

            <h1>
                <span itemprop="name">Rong Li &nbsp;&nbsp; &nbsp;&nbsp;  李 蓉 &nbsp; 
                </span>
            </h1>

            <!-- <br /> -->

            <p style="line-height:23px;">
                I am a master student at SCUT.
                <!-- <br /> -->
                <!-- <br /> -->
                Previously, I collaborated with 
                <a href="https://anhquancao.github.io/">Anh-Quan Cao</a> and Dr. <a href="https://team.inria.fr/rits/membres/raoul-de-charette/">Raoul de Charette</a> from <a href="https://team.inria.fr/rits/">Inria ASTRA</a>. I workded was an intern with <a href="https://scholar.google.com/citations?user=T2aPuoYAAAAJ&hl=en">Zhuangwei Zhuang</a> of <a href="https://en.pazhoulab.com/">Pazhou Lab</a> under the supervision of Prof. Dr. <a href="https://tanmingkui.github.io/">Mingkui Tan</a>.
                <br />
                <br />
                My current research is focused on 3D scene understanding, multi-sensor fusion and data efficient learning.
                <br />
                <!-- <br /> -->
                <!-- Contact: selirong@mail.scut.edu.cn -->
            </p>

            <p class="external">
                
                <a href="https://scholar.google.com/citations?user=M68wBgkAAAAJ&hl=en" class="first"><img src="home_files/google-scholar.svg" height="22px" width="22px">Google Scholar</a>
                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                
                <a href="https://github.com/iris0329"> <img src="home_files/github.svg" height="22px" width="22px"> GitHub</a>
                
            </p>
            <!-- <br /> -->
            <br />
        </div>
    </div>

    <div class="container">
        <h2>News</h2>
        <p> 
     
            [2022-09]&nbsp;&nbsp;&nbsp;&nbsp;1 <a href="https://arxiv.org/pdf/2210.01784.pdf">paper</a> is accepted to <a href="https://bmvc2022.org/">BMVC 2022</a>.
            
            <!-- [2022-09] 1 <a href="publication_files/BMVC -  Class-Prototypes for Contrastive Learning in Weakly-Supervised 3D Point Cloud.pdf">paper</a> is accepted to <a href="https://bmvc2022.org/">BMVC 2022</a>. -->
            <br />
            <br />

            [2022-03]&nbsp;&nbsp;&nbsp;&nbsp;We open source <a href="https://github.com/ICEORY/DeepStream/blob/master/README-ENG.md">multi sensor embedded platform</a>.

            <br />
            <br />
    
            [2021-09]&nbsp;&nbsp;&nbsp;&nbsp;1 <a href="https://arxiv.org/abs/2106.15277">paper</a> is accepted to <a href="https://iccv2021.thecvf.com/home">ICCV 2021</a>.
            
        </p>
    </div>

    <div class="container" id="publications">
        <h2>Publications 
            <!-- <small><a href="./publications.html">[Full List]</a></small>  -->
        </h2>
        <br />
        <div class="publication">
            <img src="./home_files/coarse3d.png" class="publogo" width="200 px" height="110 px"/>
            <p>
                <strong>
                    Class-Prototypes for Contrastive Learning in Weakly-Supervised 3D Point Cloud Segmentation
                </strong>
                <br />
                <br />
                <strong><font color="blue">Rong Li</font></strong>, <a href="https://anhquancao.github.io/">Anh-Quan Cao</a>, <a href="https://team.inria.fr/rits/membres/raoul-de-charette/">Raoul de Charette</a>.
                <!-- <br /> -->
                <!-- <em>arXiv Preprint, 2022</em> -->
                <br>
                <em>The British Machine Vision Conference (BMVC), 2022 
                    <!-- <font color="#e86e14">(Oral)</font>  -->
                </em>
                <!-- <br /> -->
                <br />
                <span class="links">
                    <a href="publication_files/BMVC -  Class-Prototypes for Contrastive Learning in Weakly-Supervised 3D Point Cloud.pdf">Paper</a> 
                    <a href="https://github.com/cv-rits/COARSE3D">Code</a>
                    <a href="publication_files/COARSE3D - poster.pdf">Poster</a> 
                </span>
            </p>
        </div>
 
        <br />
        <br />
        <div class="publication">
            <img src="./home_files/pmf.png" class="publogo" width="200 px" height="130 px" />
            <p>
                <strong>
                        Perception-Aware Multi-Sensor Fusion for 3D LiDAR Semantic Segmentation
                </strong>
                <br />
                <br />
                <a href="https://scholar.google.com/citations?user=T2aPuoYAAAAJ&hl=en">Zhuangwei Zhuang</a>, <strong><font color="blue">Rong Li</font></strong>, <a href="https://scholar.google.com.sg/citations?user=wN3v1coAAAAJ&hl=en">Yuanqing Li</a>, <a href="https://scholar.google.co.uk/citations?user=Mf9VHRcAAAAJ&hl=zh-CN">Kui Jia</a>, Qicheng Wang, <a href="https://tanmingkui.github.io/">Mingkui Tan</a>.
                <br>
                <em>International Conference on Computer Vision (ICCV), 2021</em>
                <!-- <br /> -->
                <br>
                <span class="links">
                    <a href="https://arxiv.org/abs/2106.15277">Paper</a>
                    <!-- <a href="https://youtu.be/giUkCKytZU8">Video</a> -->
                    <a href="https://www.bilibili.com/video/BV1JU4y1L7AM?spm_id_from=333.999.0.0&vd_source=63fa4a8b964898998fdc1a8901771f6d">Video</a>
                    <a href="https://github.com/ICEORY/PMF">Code</a>
                    <a href="./publication_files/PMF - report - by - Rong.pdf">Report</a>

                    <!-- <a href="https://xxx">Dataset</a> -->
                </span>
            </p>
        </div>
        <br />
        <br />
        <br />
        <!-- <br /> -->
        <!-- <br /> -->
    </div>

    <div class="container" id="projects">
        <h2>Projects</h2>
        <br />
        <div class="publication">
            <img src="./home_files/sensat.png" class="publogo" 
            width="200 px"  />
            <p>
                <strong>
                    SensatUrban: Urban-Scale Point Clouds Understanding Challenge
                    </a>
                </strong>

                <br />
                <br />

                is a BEV multi-sensor-fusion-based point cloud semantic segmentation implementation. Collaborated with <a href="https://scholar.google.com/citations?user=T2aPuoYAAAAJ&hl=en">Zhuangwei Zhuang</a>.
                <!-- <br />
                &nbsp;&nbsp;&nbsp;&nbsp;- XX
                <br />
                &nbsp;&nbsp;&nbsp;&nbsp;- XX
                <br />
                &nbsp;&nbsp;&nbsp;&nbsp;- XXX -->
                <!-- <br /> -->
                <br />

                <span class="links">
                    <a href="https://github.com/ICEORY/PMF">Code</a>
                    <!-- <a href="https://xxx">Dataset</a> -->
                    <a href="https://competitions.codalab.org/competitions/31519">Board</a>
                </span>

                <!-- Ref: https://buttons.github.io/ -->
                <!-- <a class="github-button" href="https://github.com/ICEORY/PMF/subscription" data-icon="octicon-eye" data-show-count="true" aria-label="Watch open-mmlab/mmhuman3d on GitHub">Watch</a>
                <a class="github-button" href="https://github.com/ICEORY/PMF/fork" data-icon="octicon-repo-forked" data-show-count="true" aria-label="Fork open-mmlab/mmhuman3d on GitHub">Fork</a>
                <a class="github-button" href="https://github.com/ICEORY/PMF" data-icon="octicon-star" data-show-count="true" aria-label="Star open-mmlab/mmhuman3d on GitHub">Star</a> -->
            </p>
        </div>
        <br />
        <br />

        <div class="publication">
            <img src="./home_files/calib.gif" class="publogo" width="200 px"  />
            <p>
                <strong>
                    An Embedded Mobile Platform Equipped with LiDAR and Camera
                    
                </strong>
                <br />
                <br />

                is an embedded mobile platform equipped with 
                <a href="https://www.livoxtech.com/horizon">Livox LiDAR</a> and <a href="https://www.hikrobotics.com/cn/machinevision/visionproduct?typeId=27&id=42">Camera</a> and is developed on <a href="https://www.nvidia.com/en-us/-machines/embedded-systems/jetson-xavier-nx/">Nvidia Jetson Xavier NX</a>. 
                <!-- It can be used to deploy multi-sensor based algorithms. -->
                Developed ith <a href="https://scholar.google.com/citations?user=T2aPuoYAAAAJ&hl=en">Zhuangwei Zhuang</a>.
                
                <!-- <br /> -->
            

                <!-- &nbsp;&nbsp;&nbsp;&nbsp;- Calibration of the internal, external matrix and distortion parameters of the sensors;
                <br />
                &nbsp;&nbsp;&nbsp;&nbsp;- Visualization of fusion results;
                <br />
                &nbsp;&nbsp;&nbsp;&nbsp;- Deployment and optimization on the embedded device; -->
                <br />
                <!-- <br /> -->

                <span class="links">
                    <!-- <a href="https://arxiv.org/abs/2106.15277">Paper</a> -->
                    <!-- &nbsp;&nbsp; -->
                    <!-- <a href="https://youtu.be/YGE5W8s8WXA">Video</a>  -->
                    <!-- &nbsp;&nbsp;&nbsp;&nbsp; -->
                    <a href="https://www.bilibili.com/video/BV1uf4y1L7Jf?spm_id_from=333.999.0.0">Video</a> 
                    <a href="https://github.com/ICEORY/DeepStream/blob/master/README-ENG.md">Code</a>
                    <!-- <a href="https://xxx">Dataset</a> -->
                    <a href="./publication_files/Deepstream - report - by - Rong.pdf">Report</a>

                </span>

    
            </p>
        </div>
        <br />
        <br />

        <!-- <div class="publication">
            <img src="./home_files/fast_rcnn.png" class="publogo" width="200 px" height="100 px" />
            <p>
                <strong>
                    <a href="xxx">Point Cloud-based Multi-Class Detection
                    </a>
                </strong>
                <br />
                <br />
                Based on work <a href="https://arxiv.org/abs/1812.04244">PointRCNN</a>, I expanded it to detect multiple classes of objects at the same time.
               
                Note: This picture is from Fast RCNN, because when this website was established, no relevant logs were found.
                <br />
      
                <br />
  
    
            </p>
        </div> -->
        <br />
        <br />
        <div class="publication">
            <img src="./home_files/teach_seg.png" class="publogo" width="200 px" height="120 px" />
            <p>
                <strong>
                    Human Segmentation for Intelligence Education
                    
                </strong>
                <br />
                <br />
                aims to reappear the obscured content on the blackboard by teacher to improve the quality of online courses. 
                <!-- It based an salient object detection method. -->
                <!-- First, Use the salient object detection algorithm to segment the people of the current video frame and obtain a mask. And retrieve the obscured content from the previous video frame according to the obtained mask. Finally, superimpose the obtained content on the current video frame.  -->
                Collaborated with <a href="https://zhuomanliu.tech/">Zhuoman Liu</a>, <a href="https://orcid.org/0000-0001-8864-908X">Gang Dai</a>, <a herf="https://www.researchgate.net/profile/Jiaqiu-Zhou">Jiaqiu Zhou</a>.
                <br />
      
                <!-- <br /> -->
                <span class="links">
                
                    <a href="https://www.youtube.com/watch?v=JzqalkgIsXc">Video</a>
                   
                </span>
    
            </p>
        </div>

        <br />
        <br />

        <div class="publication">
            <img src="./home_files/scgn.png" class="publogo" width="200 px" height="110 px" />
            <p>
                <strong>
                    Deep View Synthesis via Self-Consistent Generative Network
                    
                </strong>
                <br />
                <br />
                aims to synthesize the front view from left and right views.
                <!-- The proposed SCGN model consists of two main components, namely the view synthesis network (VSN) and the view decomposition network (VDN). VSN uses the input of different views to synthesize the target view. The VDN restores the input view from the synthesized new view to maintain the consistency of view synthesis. -->
                Coolabrate with <a href="https://zhuomanliu.tech/">Zhuoman Liu</a> and etc.
            
                <br />
      
                <!-- <br /> -->
                <span class="links">
                    <a href="https://github.com/zhuomanliu/SCGN">Code</a>
                    <a href="https://www.youtube.com/watch?v=phC4gAi8mkg">Video</a>
                    <a href="https://mailscuteducn-my.sharepoint.com/personal/selzm_mail_scut_edu_cn/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fselzm%5Fmail%5Fscut%5Fedu%5Fcn%2FDocuments%2FCVTE%2DA10%2DLab&originalPath=aHR0cHM6Ly9tYWlsc2N1dGVkdWNuLW15LnNoYXJlcG9pbnQuY29tLzpmOi9nL3BlcnNvbmFsL3NlbHptX21haWxfc2N1dF9lZHVfY24vRXR1aTB6anNFaTlDdm41MWViY3g0cHdCcDJ4Qk9EV0NxRmtJYXFDcWRyUXFBZz9ydGltZT1IZGRxTFdCUzJVZw">Dataset</a>
                </span>
    
            </p>
        </div>

        <br />
    </div>


    <div class="container", id="experience">
        <h2>Experience</h2>
        <p> 
            [2021.12 - 2022.07] &nbsp;&nbsp;&nbsp;&nbsp;
            Remote Collaboration, <a href="https://en.pazhoulab.com/">Inria-ASTRA</a>, Paris, French
            <br />
            <br />
            [2020.10 - 2021.09] &nbsp;&nbsp;&nbsp;&nbsp;
            Algorithm Intern, <a href="https://en.pazhoulab.com/">Pazhou Lab</a>, Guangzhou, China
            <br />
            <br />
            [2018.10 - 2019.06] &nbsp;&nbsp;&nbsp;&nbsp;
            Algorithm Intern, <a href="https://research.cvte.com/?locale=en-US">CVTE Research</a>, Guangzhou, China

        </p>
    </div>


    
    <div class="container">
        <h2>Education</h2>
        <p> 
            [2019 - 2022] &nbsp;&nbsp;&nbsp;&nbsp;
            M.S., <a href="https://www.scut.edu.cn/en/">South China University of Technology</a>
            <br />
            <br />
            [2015 - 2019] &nbsp;&nbsp;&nbsp;&nbsp;
            B.S., <a href="https://www.scut.edu.cn/en/">South China University of Technology</a>
            <!-- <br />
            <br />
            [2012 - 2015] &nbsp;&nbsp;&nbsp;&nbsp;
            B.S., <a href="http://www.nwnusch.cn/">The High School Attached to Northwest Normal University</a> -->
        </p>
    </div>


    <div class="container", id="honors">
        <h2>Honors</h2>
        <p> 
            [2020] &nbsp;&nbsp;&nbsp;&nbsp;
            Postgraduate Recommendation Scholarship, China 
            <br />
            <br />
            [2018] &nbsp;&nbsp;&nbsp;&nbsp;
            National Encouragement Scholarship, China
            <br />
            <br />
            [2017] &nbsp;&nbsp;&nbsp;&nbsp;
            National Encouragement Scholarship, China
        </p>
    </div>


    <div class="container", id="contact">
        <h2>Contact</h2>
        <p> 
    
            Email: &nbsp;&nbsp;&nbsp;&nbsp;
            <!-- selirong@mail.scut.edu.cn -->
            lirong0329 at qq.com
        </p>
    </div>

    <!-- For the use of github buttons -->
    <script async=async defer=defer src="https://buttons.github.io/buttons.js"></script>
</body>
</html>
